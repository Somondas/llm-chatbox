import { RecursiveCharacterTextSplitter } from "@langchain/textsplitters";
import { readFile } from "fs/promises";

import { ChatOpenAI, OpenAIEmbeddings } from "@langchain/openai";
import { log } from "console";
import "dotenv/config";

import { PromptTemplate } from "@langchain/core/prompts";
import { StringOutputParser } from "@langchain/core/output_parsers";
import { resolve } from "path";
import { retriever } from "./utils/retriever.js";
import combineDocuments from "./utils/combileDocuments.js";
import {
  RunnableSequence,
  RunnablePassthrough,
} from "@langchain/core/runnables";

// >> Starter Code --------------------
document.addEventListener("submit", (e) => {
  e.preventDefault();
  progressConversation();
});

// -> ENVs---------------------------------------
const openAIApiKey = process.env.OPENAI_API_KEY;
const sbApiKey = process.env.SP_API_KEY;
const sbUrl = process.env.SP_URL;
const groqApiKey = process.env.GROQ_API_KEY;

// >> LLM---------
const llm = new ChatOpenAI({
  apiKey: groqApiKey,
  configuration: {
    baseURL: "https://api.groq.com/openai/v1", // ğŸ‘ˆ this is required
  },
  model: "llama3-70b-8192", // âœ… Use one of Groqâ€™s supported models
});

// ? Test Code -------------------------------------

const standaloneQuestionTemplate =
  "Generate a standalone question from the given question: {question}";

const standaloneQuestionPrompt = PromptTemplate.fromTemplate(
  standaloneQuestionTemplate
);

const answerTemplate = `You are a helpful and enthusiastic support bot who can answer a given question about Scrimba based on the context provided. Try to find the answer in the context. If you really don't know the answer, say "I'm sorry, I don't know the answer to that." And direct the questioner to email help@knowsoman.com. Don't try to make up an answer. Alaways speak as if you were chatting to a friend.
context: {context}
question: {question}
answer:
`;
const answerPrompt = PromptTemplate.fromTemplate(answerTemplate);

const standaloneQuestionChain = standaloneQuestionPrompt
  .pipe(llm)
  .pipe(new StringOutputParser());

const retriverChain = RunnableSequence.from([
  (prevResult) => prevResult.standalone_question,
  retriever,
  combineDocuments,
]);
const answerChain = answerPrompt.pipe(llm).pipe(new StringOutputParser());

const chain = RunnableSequence.from([
  {
    standalone_question: standaloneQuestionChain,
    original_input: new RunnablePassthrough(),
  },
  {
    context: retriverChain,
    question: ({ original_input }) => original_input.question,
  },
  answerChain,
]);

// ? Test Code -------------------------------------

async function progressConversation() {
  const userInput = document.getElementById("user-input");
  const chatbotConversation = document.getElementById(
    "chatbot-conversation-container"
  );
  const question = userInput.value;
  userInput.value = "";

  // add human message
  const newHumanSpeechBubble = document.createElement("div");
  newHumanSpeechBubble.classList.add("speech", "speech-human");
  chatbotConversation.appendChild(newHumanSpeechBubble);
  newHumanSpeechBubble.textContent = question;
  chatbotConversation.scrollTop = chatbotConversation.scrollHeight;
  const response = await chain.invoke({
    question: question,
  });

  // add AI message
  const newAiSpeechBubble = document.createElement("div");
  newAiSpeechBubble.classList.add("speech", "speech-ai");
  chatbotConversation.appendChild(newAiSpeechBubble);
  newAiSpeechBubble.textContent = response;
  chatbotConversation.scrollTop = chatbotConversation.scrollHeight;
}
// >> Starter Code End----------------------------------------
